# âœ¨ Editor de Texto con IA (LLaMA3 + FastAPI + Streamlit)

AplicaciÃ³n web inteligente que permite generar, corregir, resumir y expandir texto con modelos locales como **LLaMA3**, usando **Ollama** en tu mÃ¡quina y una interfaz web creada con **Streamlit** y **FastAPI**.
Cuenta con autenticaciÃ³n, control por roles y funcionalidad colaborativa mediante comentarios por versiÃ³n.

---

## ğŸš€ Funcionalidades principales

âœ… Login seguro con JWT
âœ… Roles con permisos personalizados (`redactor`, `aprobador`, `diseÃ±ador`)
âœ… GeneraciÃ³n de texto vÃ­a IA (LLaMA3 + Ollama)
âœ… Historial de versiones
âœ… ReversiÃ³n de contenido
âœ… Comentarios colaborativos por versiÃ³n
âœ… Frontend interactivo con Streamlit
âœ… Backend robusto con FastAPI + SQLite

---

## ğŸ§± Estructura del proyecto

```text
editor-texto-ia/
â”œâ”€â”€ app_streamlit.py         # Interfaz web por rol
â”œâ”€â”€ main.py                  # API FastAPI
â”œâ”€â”€ auth.py                  # Login y control de roles
â”œâ”€â”€ db.py                    # Modelos SQLAlchemy + conexiÃ³n
â”œâ”€â”€ historial.py             # Manejo de versiones
â”œâ”€â”€ llama3_local.py          # ConexiÃ³n a Ollama
â”œâ”€â”€ requirements.txt         # Dependencias Python
â”œâ”€â”€ Dockerfile               # Imagen Docker de la app
â”œâ”€â”€ docker-compose.yml       # Orquestador de contenedores
â””â”€â”€ .dockerignore
```

---

## âš™ï¸ Requisitos previos

* Tener [Docker](https://www.docker.com/) y [Docker Compose](https://docs.docker.com/compose/) instalados
* Tener [Ollama](https://ollama.com/) instalado y funcionando localmente

Ejecuta Ollama en tu mÃ¡quina antes de lanzar la app:

```bash
ollama run llama3
```

---

## ğŸ³ CÃ³mo ejecutar con Docker

1. Clona el repositorio:

```bash
git clone https://github.com/jmontalvof/editor-texto-ia.git
cd editor-texto-ia
```

2. Ejecuta el proyecto:

```bash
docker-compose up --build
```

3. Accede a la aplicaciÃ³n:

* ğŸ“ API (FastAPI): [http://localhost:8000/docs](http://localhost:8000/docs)
* ğŸ’» Interfaz web (Streamlit): [http://localhost:8501](http://localhost:8501)

---

## ğŸ” Crear usuarios

Visita `http://localhost:8000/docs` y usa el endpoint:

```
POST /registro
```

Ejemplo:

```json
{
  "username": "jorge",
  "password": "1234",
  "role": "redactor"
}
```

---

## ğŸ‘¥ Roles disponibles

| Rol         | Permisos disponibles                        |
| ----------- | ------------------------------------------- |
| `redactor`  | Generar texto, ver historial personal       |
| `aprobador` | Ver historial completo, revisar comentarios |
| `diseÃ±ador` | (Reservado para funciones visuales futuras) |

---

## ğŸ“ Dependencias clave

* `fastapi`
* `uvicorn`
* `sqlalchemy`
* `streamlit`
* `requests`
* `python-jose[cryptography]`
* `passlib[bcrypt]`
* `python-multipart`

---

## âš™ï¸ PersonalizaciÃ³n

Si usas Docker y Ollama estÃ¡ instalado fuera del contenedor, asegÃºrate de que en `llama3_local.py` se use:

```python
OLLAMA_URL = "http://host.docker.internal:11434"
```

Esto permite que Docker se conecte a Ollama en tu mÃ¡quina.

---

## ğŸ¤ Contribuciones

Pull requests bienvenidas. Puedes colaborar en nuevas funcionalidades como:

* ComparaciÃ³n visual entre versiones
* IntegraciÃ³n con otros modelos
* Dashboard de estadÃ­sticas

---

## ğŸ‘¤ Autor

Proyecto creado por **Jorge**, combinando FastAPI, Streamlit y modelos locales con Ollama para construir una plataforma colaborativa de ediciÃ³n de texto con IA.

---

## ğŸ”’ Ã‰tica y seguridad en IA generativa

Esta aplicaciÃ³n estÃ¡ diseÃ±ada siguiendo principios Ã©ticos y medidas de seguridad que refuerzan su uso responsable:

### ğŸ” Privacidad y cifrado

* Contenido y versiones pueden cifrarse antes de ser almacenados.
* Se recomienda el uso de HTTPS con certificados SSL.
* JWT firmados y con expiraciÃ³n para autenticaciÃ³n segura.

### ğŸ›ï¸ Uso Ã©tico y derechos de autor

* PolÃ­ticas claras de uso mostradas en la interfaz (Streamlit).
* ProhibiciÃ³n de prompts con violencia, odio o lenguaje discriminatorio.
* Advertencia legal sobre el uso de contenido generado por IA.

### ğŸ•µï¸ï¸ ModeraciÃ³n y control de contenido

* El rol `aprobador` puede revisar versiones antes de validarlas.
* Se pueden integrar filtros automÃ¡ticos de contenido sensible (profanidad, hate speech).
* Cada versiÃ³n podrÃ¡ tener un estado: `pendiente`, `aprobado`, `rechazado`.

Estas medidas permiten que la IA generativa sea utilizada de forma segura, respetuosa y legal.

